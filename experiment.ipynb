{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow Notebook Examples\n",
    "* MLflow Tracking\n",
    "* MLflow Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to MLflow Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the Tracking URI to use the PostgreSQL DB we Configured\n",
    "\n",
    "The database is encoded as ```<dialect>+<driver>://<username>:<password>@<host>:<port>/<database>```.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "2020/07/27 09:04:54 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n2020/07/27 09:04:54 INFO mlflow.store.db.utils: Updating database tables at postgresql+psycopg2://db_user:123@localhost/mlflow_db\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Running upgrade  -> 451aebb31d03, add metric step\nINFO  [alembic.runtime.migration] Running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags\nINFO  [alembic.runtime.migration] Running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values\nINFO  [alembic.runtime.migration] Running upgrade 181f10493468 -> df50e92ffc5e, Add Experiment Tags Table\nINFO  [alembic.runtime.migration] Running upgrade df50e92ffc5e -> 7ac759974ad8, Update run tags with larger limit\nINFO  [alembic.runtime.migration] Running upgrade 7ac759974ad8 -> 89d4b8295536, create latest metrics table\nINFO  [89d4b8295536_create_latest_metrics_table_py] Migration complete!\nINFO  [alembic.runtime.migration] Running upgrade 89d4b8295536 -> 2b4d017a5e9b, add model registry tables to db\nINFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Adding registered_models and model_versions tables to database.\nINFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Migration complete!\nINFO  [alembic.runtime.migration] Running upgrade 2b4d017a5e9b -> cfd24bdc0731, Update run status constraint with killed\nINFO  [alembic.runtime.migration] Running upgrade cfd24bdc0731 -> 0a8213491aaa, drop_duplicate_killed_constraint\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\n"
    }
   ],
   "source": [
    "import os\n",
    "import mlflow\n",
    "os.environ['MLFLOW_TRACKING_URI'] = 'postgresql+psycopg2://db_user:123@localhost/mlflow_db'\n",
    "os.environ['MLFLOW_S3_ENDPOINT_URL'] = 'http://192.168.86.62:9001'\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = 'minioadmin'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'minioadmin'\n",
    "\n",
    "mlflow.create_experiment('exp', artifact_location='s3://mlflow')\n",
    "mlflow.set_experiment('exp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Tracking API\n",
    "The MLflow tracking API lets you log metrics and artifacts (files) from your data science code and see a history of your runs.\n",
    "\n",
    "The code below logs a run with one parameter (param1), one metric (foo) with three values (1,2,3), and an artifact (a text file containing \"Hello world!\").\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\n"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.start_run()\n",
    "\n",
    "# Log a parameter (key-value pair)\n",
    "mlflow.log_param(\"param1\", 5)\n",
    "# Log a metric; metrics can be updated throughout the run\n",
    "mlflow.log_metric(\"foo\", 1)\n",
    "mlflow.log_metric(\"foo\", 2)\n",
    "mlflow.log_metric(\"foo\", 3)\n",
    "# Log an artifact (output file)\n",
    "with open(\"output.txt\", \"w\") as f:\n",
    "    f.write(\"Hello world!\")\n",
    "mlflow.log_artifact(\"output.txt\")\n",
    "\n",
    "mlflow.end_run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing the Tracking UI\n",
    "We have configured MLflow to use a PostgreSQL DB for tracking. Because of this we must use the \"--backend-store-uri\" argument to tell MLflow where to find the experiments. \n",
    "\n",
    "* type in the terminal\n",
    "    * ```export MLFLOW_TRACKING_URI=postgresql+psycopg2://db_user:123@localhost/mlflow_db```\n",
    "    * ```export MLFLOW_S3_ENDPOINT_URL=http://192.168.86.62:9001```\n",
    "    * ```export AWS_ACCESS_KEY_ID=minioadmin```\n",
    "    * ```export AWS_SECRET_ACCESS_KEY=minioadmin```\n",
    "    * ```mlflow ui --backend-store-uri 'postgresql+psycopg2://db_user:123@localhost/mlflow_db'```\n",
    "* view the tracking UI by clicking the http link returned\n",
    "    * http://127.0.0.1:5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"screenshots/mlflow_ui_2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=screenshots/saved_parms_metrics_txts_2.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=screenshots/params_graph_2.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Incorporating MLflow Tracking and MLflow Models \n",
    "\n",
    "In this example MLflow Tracking is used to keep track of different hyperparameters, performance metrics, and artifacts of a linear regression model. MLflow Models is used to store the pickled trained model instance, a file describing the environment the model instance was created in, and a descriptor file that lists several \"flavors\" the model can be used in. MLflow Projects is used to package the training code. And lastly MLflow Models is used to deploy the model to a simple HTTP server.\n",
    "\n",
    "This tutorial uses a dataset to predict the quality of wine based on quantitative features like the wine's \"fixed acidity\", \"pH\", \"residual sugar\", and so on. The dataset is from UCI's machine learning repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "First, train a linear regression model that takes two hyperparameters: alpha and l1_ratio.\n",
    "\n",
    "This example uses the familiar pandas, numpy, and sklearn APIs to create a simple machine learning model. The MLflow tracking APIs log information about each training run like hyperparameters (alpha and l1_ratio) used to train the model, and metrics (root mean square error, mean absolute error, and r2) used to evaluate the model. The example also serializes the model in a format that MLflow knows how to deploy.\n",
    "\n",
    "Each time you run the example, MLflow logs information about your experiment runs in the directory mlruns.\n",
    "\n",
    "You can run the example through the .py script using the following command.\n",
    "* ```python train.py <alpha> <l1_ratio>```\n",
    "\n",
    "Or you can also use the notebook code below that does the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wine Quality Sample\n",
    "def train(in_alpha, in_l1_ratio):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.linear_model import ElasticNet\n",
    "    import mlflow\n",
    "    import mlflow.sklearn\n",
    "\n",
    "    def eval_metrics(actual, pred):\n",
    "        rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "        mae = mean_absolute_error(actual, pred)\n",
    "        r2 = r2_score(actual, pred)\n",
    "        return rmse, mae, r2\n",
    "\n",
    "    np.random.seed(40)\n",
    "\n",
    "    # Read the wine-quality csv file from the URL\n",
    "    csv_url =\\\n",
    "        'http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
    "    data = pd.read_csv(csv_url, sep=';')\n",
    "\n",
    "    # Split the data into training and test sets. (0.75, 0.25) split.\n",
    "    train, test = train_test_split(data)\n",
    "\n",
    "    # The predicted column is \"quality\" which is a scalar from [3, 9]\n",
    "    train_x = train.drop([\"quality\"], axis=1)\n",
    "    test_x = test.drop([\"quality\"], axis=1)\n",
    "    train_y = train[[\"quality\"]]\n",
    "    test_y = test[[\"quality\"]]\n",
    "\n",
    "    # Set default values if no alpha is provided\n",
    "    if float(in_alpha) is None:\n",
    "        alpha = 0.5\n",
    "    else:\n",
    "        alpha = float(in_alpha)\n",
    "\n",
    "    # Set default values if no l1_ratio is provided\n",
    "    if float(in_l1_ratio) is None:\n",
    "        l1_ratio = 0.5\n",
    "    else:\n",
    "        l1_ratio = float(in_l1_ratio)\n",
    "\n",
    "    # Useful for multiple runs   \n",
    "    with mlflow.start_run():\n",
    "        # Execute ElasticNet\n",
    "        lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n",
    "        lr.fit(train_x, train_y)\n",
    "\n",
    "        # Evaluate Metrics\n",
    "        predicted_qualities = lr.predict(test_x)\n",
    "        (rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)\n",
    "\n",
    "        # Print out metrics\n",
    "        print(\"Elasticnet model (alpha=%f, l1_ratio=%f):\" % (alpha, l1_ratio))\n",
    "        print(\"  RMSE: %s\" % rmse)\n",
    "        print(\"  MAE: %s\" % mae)\n",
    "        print(\"  R2: %s\" % r2)\n",
    "\n",
    "        # Log parameter, metrics, and model to MLflow\n",
    "        mlflow.log_param(\"alpha\", alpha)\n",
    "        mlflow.log_param(\"l1_ratio\", l1_ratio)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "\n",
    "        mlflow.sklearn.log_model(lr, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nElasticnet model (alpha=0.250000, l1_ratio=0.250000):\n  RMSE: 0.7380489682487518\n  MAE: 0.5690312554727687\n  R2: 0.22820122626467798\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nElasticnet model (alpha=0.250000, l1_ratio=0.500000):\n  RMSE: 0.7489307838571879\n  MAE: 0.5806946169417598\n  R2: 0.20527460024945365\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nElasticnet model (alpha=0.250000, l1_ratio=0.750000):\n  RMSE: 0.7662476663327954\n  MAE: 0.5985976516559471\n  R2: 0.1680982095420568\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nElasticnet model (alpha=0.500000, l1_ratio=0.250000):\n  RMSE: 0.7596554775612442\n  MAE: 0.5913132541174235\n  R2: 0.18235068599935977\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nElasticnet model (alpha=0.500000, l1_ratio=0.500000):\n  RMSE: 0.7931640229276851\n  MAE: 0.6271946374319586\n  R2: 0.10862644997792614\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nElasticnet model (alpha=0.500000, l1_ratio=0.750000):\n  RMSE: 0.8318658159940802\n  MAE: 0.6651040854928951\n  R2: 0.019516509058132292\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nElasticnet model (alpha=0.750000, l1_ratio=0.250000):\n  RMSE: 0.7837307525653582\n  MAE: 0.6165474987409884\n  R2: 0.1297029612600864\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nElasticnet model (alpha=0.750000, l1_ratio=0.500000):\n  RMSE: 0.8318702776765884\n  MAE: 0.6651291355677875\n  R2: 0.019505991453757976\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nElasticnet model (alpha=0.750000, l1_ratio=0.750000):\n  RMSE: 0.8331799787336064\n  MAE: 0.669234506901795\n  R2: 0.016416170929074214\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\n"
    }
   ],
   "source": [
    "# Run the above training code with different hyperparameters (9 runs)\n",
    "alphas = [0.25, 0.5, 0.75]\n",
    "l1_ratios = [0.25, 0.5, 0.75]\n",
    "for i in alphas:\n",
    "    for j in l1_ratios:\n",
    "        train(i,j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the Models\n",
    "Next, use the MLflow UI to compare the models that you have produced.\n",
    "\n",
    "* type the following command into the terminal\n",
    "    * ```export MLFLOW_TRACKING_URI=postgresql+psycopg2://db_user:123@localhost/mlflow_db```\n",
    "    * ```export MLFLOW_S3_ENDPOINT_URL=http://192.168.86.62:9001```\n",
    "    * ```export AWS_ACCESS_KEY_ID=minioadmin```\n",
    "    * ```export AWS_SECRET_ACCESS_KEY=minioadmin```\n",
    "    * ```mlflow ui --backend-store-uri 'postgresql+psycopg2://db_user:123@localhost/mlflow_db'```\n",
    "* a link will pop up in the terminal and you can view the mlflow ui at\n",
    "    * http://127.0.0.1:5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"screenshots/tutorial_1_runs_2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the search feature to quickly filter out many models. For example, the query (metrics.rmse < 0.8) returns all the models with root mean square error less than 0.8. For more complex manipulations, you can download this table as a CSV and use your favorite data munging software to analyze it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"screenshots/tutorial_1_runs_filtered_2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a Model from Tracking\n",
    "* ```mlflow.<model_flavor>.load_model(modelpath)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 's3://mlflow/<run_id>/artifacts/model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "RMSE: 0.7380489682487518\n  MAE: 0.5690312554727687\n  R2: 0.22820122626467798\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow.sklearn\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def eval_metrics(actual, pred):\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    r2 = r2_score(actual, pred)\n",
    "    return rmse, mae, r2\n",
    "\n",
    "np.random.seed(40)\n",
    "\n",
    "# Read the wine-quality csv file from the URL\n",
    "csv_url =\\\n",
    "    'http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
    "try:\n",
    "    data = pd.read_csv(csv_url, sep=';')\n",
    "except Exception as e:\n",
    "    logger.exception(\n",
    "        \"Unable to download training & test CSV, check your internet connection. Error: %s\", e)\n",
    "# Split the data into training and test sets. (0.75, 0.25) split.\n",
    "train, test = train_test_split(data)\n",
    "# The predicted column is \"quality\" which is a scalar from [3, 9]\n",
    "train_x = train.drop([\"quality\"], axis=1)\n",
    "test_x = test.drop([\"quality\"], axis=1)\n",
    "train_y = train[[\"quality\"]]\n",
    "test_y = test[[\"quality\"]]\n",
    "\n",
    "# Loading the model\n",
    "loaded_model = mlflow.sklearn.load_model(model_path)\n",
    "\n",
    "# Evaluate Metrics\n",
    "predicted_qualities = loaded_model.predict(test_x)\n",
    "(rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)\n",
    "\n",
    "# Print out metrics\n",
    "print(\"  RMSE: %s\" % rmse)\n",
    "print(\"  MAE: %s\" % mae)\n",
    "print(\"  R2: %s\" % r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packaging Training Code in a Conda Environment with MLflow Projects\n",
    "\n",
    "Now that you have your training code, you can package it so that other data scientists can easily reuse the model, or so that you can run the training remotely. \n",
    "\n",
    "You do this by using MLflow Projects to specify the dependencies and entry points to your code. The MLproject file specifies that the project has the dependencies located in a conda environment called conda.yaml and has one entry point that takes two parameters: alpha and l1_ratio. \n",
    "\n",
    "Note: In order for the above logic to be ran as a MLflow Project we have converted the train() function above into a python script named train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=screenshots/mlproject.png width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this project use mlflow run on the folder containing the MLproject file.\n",
    "* ```export MLFLOW_TRACKING_URI=postgresql+psycopg2://db_user:123@localhost/mlflow_db```\n",
    "* ```export MLFLOW_S3_ENDPOINT_URL=http://192.168.86.62:9001```\n",
    "* ```export AWS_ACCESS_KEY_ID=minioadmin```\n",
    "* ```export AWS_SECRET_ACCESS_KEY=minioadmin```\n",
    "* ```mlflow run ../conda_env -P alpha=1.0 -P l1_ratio=1.0 --experiment-name exp```\n",
    "\n",
    "After running this command, MLflow runs your training code in a new Conda environment with the dependencies specified in conda.yaml.\n",
    "\n",
    "If a repository has an MLproject file you can also run a project directly from GitHub. This tutorial lives in the https://bitbucket.org/noodleai/mlflow_demos repository which you can run with the following command. The symbol \"#\" is used to move into a subdirectory of the repo. The \"--version\" argument can be used to run code from a different branch. You will need to type your username into the below command. \n",
    "* ```export MLFLOW_TRACKING_URI=postgresql+psycopg2://db_user:123@localhost/mlflow_db```\n",
    "* ```export MLFLOW_S3_ENDPOINT_URL=http://192.168.86.62:9001```\n",
    "* ```export AWS_ACCESS_KEY_ID=minioadmin```\n",
    "* ```export AWS_SECRET_ACCESS_KEY=minioadmin```\n",
    "* ```mlflow run https://<username>@bitbucket.org/noodleai/mlflow_demos.git#conda_env -P alpha=1.0 -P l1_ratio=0.8 --experiment-name exp```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serving the Model\n",
    "\n",
    "Now that you have packaged your model using the MLproject convention and have identified the best model, it is time to deploy the model using MLflow Models. An MLflow Model is a standard format for packaging machine learning models that can be used in a variety of downstream tools - for example, real-time serving through a REST API or batch inference on Apache Spark. \n",
    "\n",
    "In the example training code, after training the linear regression model, a function in MLflow saved the model as an artifact within the run. \n",
    "\n",
    "* mlflow.sklearn.log_model(lr, \"model\")\n",
    "\n",
    "To view this artifact, you can use the UI again. When you click a date in the list of experiment runs you'll see this page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=screenshots/model_artifacts_2.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the bottom, you can see that the call to mlflow.sklearn.log_model produced three files in s3://mlflow/<run_id>/artifacts/model. The first file, MLmodel, is a metadata file that tells MLflow how to load the model. The second file is a conda.yaml that contains the model dependencies from the conda environment. The third file, model.pkl, is a serialized version of the linear regression model that you trained. \n",
    "\n",
    "In this example, you can use this MLmodel format with MLflow to deploy a local REST server that can serve predictions. \n",
    "\n",
    "We must set our environment variables in the terminal before running the serve command. To deploy the server, run the following commands.\n",
    "* ```export MLFLOW_TRACKING_URI=postgresql+psycopg2://db_user:123@localhost/mlflow_db```\n",
    "* ```export MLFLOW_S3_ENDPOINT_URL=http://192.168.86.62:9001```\n",
    "* ```export AWS_ACCESS_KEY_ID=minioadmin```\n",
    "* ```export AWS_SECRET_ACCESS_KEY=minioadmin```\n",
    "* ```mlflow models serve -m s3://mlflow/<run_id>/artifacts/model -p 1234```\n",
    "\n",
    "Note:\n",
    "The version of Python used to create the model must be the same as the one running mlflow models serve. If this is not the case, you may see the error. \n",
    "* UnicodeDecodeError: 'ascii' codec can't decode byte 0x9f in position 1: ordinal not in range(128) or raise ValueError, \"unsupported pickle protocol: %d\"\n",
    "\n",
    "Once you have deployed the server, you can pass it some sample data and see the predictions. The following example uses curl to send a JSON-serialized pandas DataFrame with the split orientation to the model server. For more information about the input data formats accepted by the model server, see the MLflow deployment tools documentation.\n",
    "* ```curl -X POST -H \"Content-Type:application/json; format=pandas-split\" --data '{\"columns\":[\"alcohol\", \"chlorides\", \"citric acid\", \"density\", \"fixed acidity\", \"free sulfur dioxide\", \"pH\", \"residual sugar\", \"sulphates\", \"total sulfur dioxide\", \"volatile acidity\"],\"data\":[[12.8, 0.029, 0.48, 0.98, 6.2, 29, 3.33, 1.2, 0.39, 75, 0.66]]}' http://127.0.0.1:1234/invocations```\n",
    "\n",
    "The server should respond with output similar to: \n",
    "```[3.7783608837127516]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1595865630819",
   "display_name": "Python 3.8.3 64-bit ('mlflow_demos': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}